Sample shape: (100000, 7)

Running simulations for each ablation configuration...

Simulating for commoncrawl...
Top-128 samples shape: (128, 7)

Optimal data mixture for commoncrawl - Commoncrawl:
       Domain  Commoncrawl Weight
        arxiv            0.011382
        books            0.001577
           c4            0.050477
  commoncrawl            0.934739
       github            0.000057
stackexchange            0.000082
    wikipedia            0.001685
train_dw: "0.01,0.00,0.05,0.93,0.00,0.00,0.00"

Simulating for T1...
Top-128 samples shape: (128, 7)

Optimal data mixture for T1 - gsm8k+arc_easy+arc_challenge:
       Domain  gsm8k+arc_easy+arc_challenge Weight
        arxiv                             0.009329
        books                             0.062969
           c4                             0.345613
  commoncrawl                             0.573518
       github                             0.000396
stackexchange                             0.005615
    wikipedia                             0.002559
train_dw: "0.01,0.06,0.35,0.57,0.00,0.01,0.00"

Simulating for T2...
Top-128 samples shape: (128, 7)

Optimal data mixture for T2 - gsm8k+hellaswag:
       Domain  gsm8k+hellaswag Weight
        arxiv                0.010871
        books                0.008478
           c4                0.845387
  commoncrawl                0.104320
       github                0.000586
stackexchange                0.027940
    wikipedia                0.002418
train_dw: "0.01,0.01,0.85,0.10,0.00,0.03,0.00"

Simulating for T3...
Top-128 samples shape: (128, 7)

Optimal data mixture for T3 - gsm8k+piqa:
       Domain  gsm8k+piqa Weight
        arxiv           0.003415
        books           0.014374
           c4           0.889262
  commoncrawl           0.073177
       github           0.000652
stackexchange           0.013137
    wikipedia           0.005983
train_dw: "0.00,0.01,0.89,0.07,0.00,0.01,0.01"

Simulating for T4...
Top-128 samples shape: (128, 7)

Optimal data mixture for T4 - gsm8k+logiqa:
       Domain  gsm8k+logiqa Weight
        arxiv             0.002853
        books             0.018543
           c4             0.899591
  commoncrawl             0.060425
       github             0.000110
stackexchange             0.016314
    wikipedia             0.002165
train_dw: "0.00,0.02,0.90,0.06,0.00,0.02,0.00"

Simulating for T5...
Top-128 samples shape: (128, 7)

Optimal data mixture for T5 - gsm8k+sciq:
       Domain  gsm8k+sciq Weight
        arxiv           0.009664
        books           0.015185
           c4           0.764788
  commoncrawl           0.202571
       github           0.000299
stackexchange           0.005831
    wikipedia           0.001662
train_dw: "0.01,0.02,0.76,0.20,0.00,0.01,0.00"

Simulating for T6...
Top-128 samples shape: (128, 7)

Optimal data mixture for T6 - gsm8k+kodcode+arc_easy+arc_challenge:
       Domain  gsm8k+kodcode+arc_easy+arc_challenge Weight
        arxiv                                     0.006824
        books                                     0.025685
           c4                                     0.266358
  commoncrawl                                     0.574274
       github                                     0.076469
stackexchange                                     0.049438
    wikipedia                                     0.000952
train_dw: "0.01,0.03,0.27,0.57,0.08,0.05,0.00"

Simulating for T7...
Top-128 samples shape: (128, 7)

Optimal data mixture for T7 - gsm8k+kodcode+hellaswag:
       Domain  gsm8k+kodcode+hellaswag Weight
        arxiv                        0.004036
        books                        0.010869
           c4                        0.596907
  commoncrawl                        0.134667
       github                        0.138652
stackexchange                        0.113987
    wikipedia                        0.000881
train_dw: "0.00,0.01,0.60,0.13,0.14,0.11,0.00"

Simulating for T8...
Top-128 samples shape: (128, 7)

Optimal data mixture for T8 - all_tasks:
       Domain  all_tasks Weight
        arxiv          0.004110
        books          0.026823
           c4          0.635889
  commoncrawl          0.248944
       github          0.044954
stackexchange          0.035339
    wikipedia          0.003941
train_dw: "0.00,0.03,0.64,0.25,0.04,0.04,0.00"

Simulating for T9...
Top-128 samples shape: (128, 7)

Optimal data mixture for T9 - 6_tasks_without_kodcode_gsm8k:
       Domain  6_tasks_without_kodcode_gsm8k Weight
        arxiv                              0.018193
        books                              0.149363
           c4                              0.597515
  commoncrawl                              0.232676
       github                              0.000067
stackexchange                              0.001594
    wikipedia                              0.000593
train_dw: "0.02,0.15,0.60,0.23,0.00,0.00,0.00"
